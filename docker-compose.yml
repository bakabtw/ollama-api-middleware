services:
  ollama-api-middleware:
    build:
      context: .
    container_name: ollama-api-middleware
    restart: unless-stopped
    environment:
      - OLLAMA_HOST=http://ollama:11434
      - STEP1_MODEL=generator
      - STEP2_MODEL=processor
    ports:
      - "80:80"

  ollama:
    image: ollama/ollama:0.3.11
    container_name: ollama
    restart: unless-stopped
    volumes:
      - ./ollama:/root/.ollama 
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
